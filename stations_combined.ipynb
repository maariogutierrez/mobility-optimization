{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "Ca_8FgZQePSU",
        "outputId": "3098ba9d-4f5e-4e32-fbf9-e44612a2337f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "colab=True\n",
        "df = pd.read_csv('rome_clean.csv') if colab == True else pd.read_csv('/data/processed/rome_clean.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VzrYwT7geer6",
        "outputId": "869e1a03-f559-4707-f658-a49633ecd66e"
      },
      "outputs": [],
      "source": [
        "coords_df = df[['lonO', 'latO', 'lonD', 'latD', 'idS', 'dis']].copy()\n",
        "\n",
        "def categorize_distance(dis):\n",
        "    if dis < 2500:\n",
        "        return 'corto'\n",
        "    elif dis < 5000:\n",
        "        return 'medio'\n",
        "    else:\n",
        "        return 'largo'\n",
        "\n",
        "def wait(dis):\n",
        "    if dis == 'corto':\n",
        "        return 300\n",
        "    elif dis == 'medio':\n",
        "        return 420\n",
        "    else:\n",
        "        return 600\n",
        "\n",
        "coords_df['type'] = coords_df['dis'].apply(categorize_distance)\n",
        "coords_df['wait'] = coords_df['type'].apply(wait)\n",
        "coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wCk8y9FIeq-I",
        "outputId": "a8403048-3841-4282-edde-2ca1255e1e2c"
      },
      "outputs": [],
      "source": [
        "origin_df = coords_df[['lonO', 'latO', 'idS', 'dis', 'type', 'wait']].copy()\n",
        "origin_df.rename(columns={'lonO': 'lon', 'latO': 'lat'}, inplace=True)\n",
        "origin_df['origin'] = True\n",
        "\n",
        "destination_df = coords_df[['lonD', 'latD', 'idS', 'dis', 'type', 'wait']].copy()\n",
        "destination_df.rename(columns={'lonD': 'lon', 'latD': 'lat'}, inplace=True)\n",
        "destination_df['origin'] = False\n",
        "\n",
        "combined_coords_df = pd.concat([origin_df, destination_df], ignore_index=True)\n",
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsWmfFu8ehoI"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "\n",
        "def clusterizar_coordenadas(df, coords_cols, k_values=[100,150,200,250,300,350,400], random_state=42):\n",
        "    \"\"\"\n",
        "    Clusteriza un DataFrame usando KMeans para varios valores de k con barra de progreso.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con las coordenadas.\n",
        "        coords_cols (list): Lista con los nombres de las columnas de coordenadas, e.g., ['lat','lon'].\n",
        "        k_values (list): Lista de valores de k a probar.\n",
        "        random_state (int): Semilla para reproducibilidad.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con nuevas columnas cluster_k para cada valor de k.\n",
        "    \"\"\"\n",
        "    for k in tqdm(k_values, desc=\"Clustering\"):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
        "        df[f'cluster_{k}'] = kmeans.fit_predict(df[coords_cols])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6_yNdG-1enDW",
        "outputId": "3e5323c3-e355-47ad-8ff3-ca81ad268207"
      },
      "outputs": [],
      "source": [
        "k_values = list(range(150, 310, 10))\n",
        "combined_coords_df = clusterizar_coordenadas(combined_coords_df, coords_cols=['lat','lon'], k_values=[190])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-ULOagHhfaq1",
        "outputId": "36f1d365-32ad-448e-99d2-c946037749b4"
      },
      "outputs": [],
      "source": [
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0aE57VTfdzX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def haversine_dist(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calcula la distancia Haversine en metros entre dos puntos (lat, lon).\n",
        "    \"\"\"\n",
        "    R = 6371000  # Radio de la Tierra en metros\n",
        "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
        "    dphi = np.radians(lat2 - lat1)\n",
        "    dlambda = np.radians(lon2 - lon1)\n",
        "\n",
        "    a = np.sin(dphi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    return R * c\n",
        "\n",
        "def viajes_fuera_de_radio(df, coords_cols=['lat','lon'], k_values=[100,150,200,250,300,350,400], velocidad_kmh=5):\n",
        "    resultados = {}\n",
        "\n",
        "    for k in tqdm(k_values, total=len(k_values)):\n",
        "        cluster_col = f'cluster_{k}'\n",
        "        fuera = 0\n",
        "\n",
        "        # Obtener centroides\n",
        "        centroides = df.groupby(cluster_col)[coords_cols].mean()\n",
        "\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            centroide = centroides.loc[row[cluster_col]]\n",
        "            distancia_m = haversine_dist(row[coords_cols[0]], row[coords_cols[1]],\n",
        "                                        centroide[coords_cols[0]], centroide[coords_cols[1]])\n",
        "\n",
        "            max_dist = (velocidad_kmh * 1000 / 3600) * row['wait']\n",
        "\n",
        "            if distancia_m > max_dist:\n",
        "                fuera += 1\n",
        "\n",
        "        resultados[k] = fuera\n",
        "\n",
        "    return resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2LsOfJKfmtM",
        "outputId": "815d2ae8-604f-4cd5-d4f0-0fdee19fabf5"
      },
      "outputs": [],
      "source": [
        "combined_coords_results = viajes_fuera_de_radio(combined_coords_df, k_values=[190])\n",
        "combined_coords_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuLX5xdnfsrJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calcular_silhouette(df, coords_cols=['lat','lon'], k_values=[100,150,200,250,300,350,400]):\n",
        "    \"\"\"\n",
        "    Calcula el silhouette score para cada clustering guardado en cluster_k.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con las coordenadas y las columnas cluster_k.\n",
        "        coords_cols (list): Columnas de lat/lon.\n",
        "        k_values (list): Valores de k.\n",
        "\n",
        "    Returns:\n",
        "        dict: {k: silhouette score}\n",
        "    \"\"\"\n",
        "    scores = {}\n",
        "    X = df[coords_cols].values\n",
        "\n",
        "    for k in tqdm(k_values, total=len(k_values)):\n",
        "        cluster_col = f'cluster_{k}'\n",
        "        labels = df[cluster_col].values\n",
        "        if len(set(labels)) > 1:  # Silhouette necesita al menos 2 clusters\n",
        "            score = silhouette_score(X, labels)\n",
        "        else:\n",
        "            score = 0\n",
        "        scores[k] = score\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "z_NWLTwTf4zi",
        "outputId": "5aeb5bfa-0e44-4cd6-92e6-9c51b664cb24"
      },
      "outputs": [],
      "source": [
        "sil_scores = calcular_silhouette(combined_coords_df, k_values=[190])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJauCrpKgWdx"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_silhouette_vs_viajes(k_values, silhouette_scores, viajes_fuera):\n",
        "    \"\"\"\n",
        "    Grafica silhouette score y viajes fuera de radio en función de k.\n",
        "\n",
        "    Args:\n",
        "        k_values (list): Lista de valores de k.\n",
        "        silhouette_scores (list): Lista de silhouette scores correspondientes a cada k.\n",
        "        viajes_fuera (dict): Diccionario {k: número de viajes fuera de radio}.\n",
        "    \"\"\"\n",
        "    # Convertir dict de viajes a lista en el mismo orden de k_values\n",
        "    viajes = [viajes_fuera[k] for k in k_values]\n",
        "    silhouette_scores = [silhouette_scores[k] for k in k_values]\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Línea de silhouette score\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=k_values,\n",
        "        y=silhouette_scores,\n",
        "        name='Silhouette Score',\n",
        "        mode='lines+markers',\n",
        "        yaxis='y1'\n",
        "    ))\n",
        "\n",
        "    # Línea de viajes fuera de radio\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=k_values,\n",
        "        y=viajes,\n",
        "        name='Viajes fuera de radio',\n",
        "        mode='lines+markers',\n",
        "        yaxis='y2'\n",
        "    ))\n",
        "\n",
        "    # Configurar ejes\n",
        "    fig.update_layout(\n",
        "        title='Silhouette Score vs Viajes fuera de radio',\n",
        "        xaxis=dict(title='Número de clusters k'),\n",
        "        yaxis=dict(title='Silhouette Score', side='left'),\n",
        "        yaxis2=dict(title='Viajes fuera de radio', overlaying='y', side='right'),\n",
        "        legend=dict(x=0.1, y=1.1, orientation='h')\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJmff3-MgbAz"
      },
      "outputs": [],
      "source": [
        "plot_silhouette_vs_viajes(k_values, sil_scores, combined_coords_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI6IGTeLi4Qk"
      },
      "source": [
        "Elegimos 190 porque es donde parece que se estanca un poco el silhouette score y la curva de viajes fuera de radio. A partir de 220, empieza a crecer pero consideramos que ya es un número muy elevado de estaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QxNC7NELikPu",
        "outputId": "039de534-9f30-4f07-93eb-c337d1db3ed1"
      },
      "outputs": [],
      "source": [
        "combined_coords_df = combined_coords_df[['lon', 'lat', 'idS', 'type', 'origin', 'cluster_190']]\n",
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cXnpI8zJi2Ms",
        "outputId": "9a40f7a1-01d7-4e7b-e915-3485b369675a"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "import pandas as pd\n",
        "\n",
        "cluster_col = 'cluster_190'\n",
        "coords_cols = ['lat', 'lon']\n",
        "\n",
        "# Calcular centroides\n",
        "centroides = combined_coords_df.groupby(cluster_col)[coords_cols].mean().reset_index()\n",
        "\n",
        "# Crear mapa centrado en los puntos\n",
        "mapa = folium.Map(location=[combined_coords_df['lat'].mean(), combined_coords_df['lon'].mean()], zoom_start=13)\n",
        "\n",
        "# Colores para clusters\n",
        "colores = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightblue', 'cadetblue', 'darkgreen', 'pink']\n",
        "\n",
        "# Añadir centroides\n",
        "for i, row in centroides.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['lat'], row['lon']],\n",
        "        popup=f\"Cluster {row[cluster_col]}\",\n",
        "        icon=folium.Icon(color=colores[i % len(colores)], icon='star')\n",
        "    ).add_to(mapa)\n",
        "\n",
        "# Añadir puntos\n",
        "for i, row in combined_coords_df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row['lat'], row['lon']],\n",
        "        radius=3,\n",
        "        color=colores[row['cluster_190'] % len(colores)],\n",
        "        fill=True,\n",
        "        fill_opacity=0.6\n",
        "    ).add_to(mapa)\n",
        "\n",
        "mapa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnUbxIZTmL88"
      },
      "source": [
        "Ahora vamos a agrupar estaciones en un radio de cercania, para que si dos estaciones están muy juntas, se agrupen. Para calcular el punto medio, vamos a tener en cuenta el número de viajes en cada cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muay9WhymtA5"
      },
      "outputs": [],
      "source": [
        "centroides.rename({'cluster_190': 'cluster'}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDN7kEXNO0ZN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "XjDD7r-QoiAh",
        "outputId": "1b3afd01-e695-4c6e-c20a-625e3d52c3f7"
      },
      "outputs": [],
      "source": [
        "combined_coords_df.groupby('cluster_190')['origin'].agg('count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BZHVey-joevl",
        "outputId": "44514deb-4658-4441-df20-704736fcf41c"
      },
      "outputs": [],
      "source": [
        "centroides['num_points'] = combined_coords_df.groupby('cluster_190')['origin'].agg('count')\n",
        "centroides.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5pMGjrRm8Ni"
      },
      "outputs": [],
      "source": [
        "# !pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcUC7pvTmDCx"
      },
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "\n",
        "RADIUS = 200 # Radius in kilometers\n",
        "\n",
        "centroides_new = []\n",
        "combined_centroids = []\n",
        "\n",
        "for _, row in centroides.iterrows():\n",
        "  id = row['cluster']\n",
        "  if id not in combined_centroids:\n",
        "    lat, lon = row['lat'], row['lon']\n",
        "\n",
        "    nearby_dests = []\n",
        "\n",
        "    # Collect nearby centroids (excluding itself)\n",
        "    for _, row2 in centroides.iterrows():\n",
        "      id2 = row2['cluster']\n",
        "      if id != id2 and id2 not in combined_centroids:\n",
        "        lat2, lon2 = row2['lat'], row2['lon']\n",
        "        distance = haversine((lat, lon), (lat2, lon2), unit=Unit.METERS)\n",
        "        if distance <= RADIUS:\n",
        "          nearby_dests.append(row2)\n",
        "          combined_centroids.append(id2)\n",
        "\n",
        "    # Calculate weighted average for new_lat and new_lon\n",
        "    weighted_lat_sum = lat * row['num_points']\n",
        "    weighted_lon_sum = lon * row['num_points']\n",
        "    total_weight = row['num_points']\n",
        "\n",
        "    for nearby_row in nearby_dests:\n",
        "      weighted_lat_sum += nearby_row['lat'] * nearby_row['num_points']\n",
        "      weighted_lon_sum += nearby_row['lon'] * nearby_row['num_points']\n",
        "      total_weight += nearby_row['num_points']\n",
        "\n",
        "    if total_weight > 0:\n",
        "      new_lat = weighted_lat_sum / total_weight\n",
        "      new_lon = weighted_lon_sum / total_weight\n",
        "    else: # Fallback, should ideally not be reached if row['num_points'] > 0\n",
        "      new_lat = lat\n",
        "      new_lon = lon\n",
        "\n",
        "    # This part is currently not adding anything to centroides_new,\n",
        "    # you might want to append the new_lat, new_lon, and other relevant info\n",
        "    # to centroides_new list for further processing.\n",
        "    centroides_new.append({'cluster': id, 'lat': new_lat, 'lon': new_lon, 'num_points': total_weight})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5wACs5CqovH"
      },
      "outputs": [],
      "source": [
        "len(centroides_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1ir-SLS0PQQP",
        "outputId": "74a29c84-300e-4d2a-aab1-f3c5c86db630"
      },
      "outputs": [],
      "source": [
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORNFJuMTsIYF"
      },
      "outputs": [],
      "source": [
        "centroides_new = pd.DataFrame(centroides_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "ScGbojOfqq2F",
        "outputId": "8f71006c-a469-4117-bdb3-186e94406e08"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURACIÓN\n",
        "# =========================================================\n",
        "colores = ['red', 'blue', 'green', 'purple', 'orange',\n",
        "           'darkred', 'lightblue', 'cadetblue', 'darkgreen', 'pink']\n",
        "\n",
        "# Repetimos colores si hay más clusters que colores disponibles\n",
        "color_map = {}\n",
        "for idx, row1 in centroides_new.iterrows():\n",
        "    color_map[row1['cluster']] = colores[idx % len(colores)]\n",
        "\n",
        "# =========================================================\n",
        "# CREAR MAPA\n",
        "# =========================================================\n",
        "m = folium.Map(location=[41.90, 12.48], zoom_start=12)\n",
        "\n",
        "# Capa para cluster fusionado\n",
        "fused_layer = folium.FeatureGroup(name=\"Fused Centroids\").add_to(m)\n",
        "\n",
        "# Capa de círculos 50m para destinos aislados\n",
        "dest_radius_layer = folium.FeatureGroup(name=\"Destinations 50m Radius\").add_to(m)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# PINTAR CENTROIDES FUSIONADOS\n",
        "# =========================================================\n",
        "for _, row in centroides_new.iterrows():\n",
        "    cid = row[\"cluster\"]\n",
        "    lat = row[\"lat\"]\n",
        "    lon = row[\"lon\"]\n",
        "\n",
        "    # --- MARCADOR ---\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        icon=folium.Icon(\n",
        "            icon=\"bolt\",\n",
        "            prefix=\"fa\",\n",
        "            color=color_map[cid]\n",
        "        ),\n",
        "        popup=(\n",
        "            f\"<b>Cluster {cid}</b><br>\"\n",
        "            f\"lat: {lat:.5f}<br>\"\n",
        "            f\"lon: {lon:.5f}\"\n",
        "        )\n",
        "    ).add_to(fused_layer)\n",
        "\n",
        "    folium.Circle(\n",
        "        location=[lat, lon],\n",
        "        radius=200,  # 50 metros\n",
        "        color=color_map[cid],\n",
        "        fill=True,\n",
        "        fill_opacity=0.15\n",
        "    ).add_to(dest_radius_layer)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# CAPAS\n",
        "# =========================================================\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "# Mostrar\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvicgT6ar0Dt",
        "outputId": "91624696-0c43-4ff4-a07e-ada519491e47"
      },
      "outputs": [],
      "source": [
        "!pip install shapely osmnx networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JIJb7dWPeat"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "2cISm-sLsoVm",
        "outputId": "49a6823e-a904-4c7d-80ce-0a8b3b63f1d0"
      },
      "outputs": [],
      "source": [
        "#!pip install shapely osmnx networkx\n",
        "import json\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "from shapely.geometry import Point, Polygon, MultiPolygon\n",
        "from shapely.ops import nearest_points\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================================================\n",
        "# 1. LOAD AND PREPARE RESTRICTED ZONES\n",
        "# =========================================================\n",
        "\n",
        "# Load the content you provided\n",
        "json_data = json.load(open(\"restricted_zones.json\"))\n",
        "\n",
        "# The JSON coordinates are [Lon, Lat] (GeoJSON standard).\n",
        "# We convert them to Shapely Polygons.\n",
        "polygons_list = []\n",
        "for poly_coords in json_data[\"restricted_polygons\"]:\n",
        "    # Ensure the polygon is closed (first point == last point)\n",
        "    if poly_coords[0] != poly_coords[-1]:\n",
        "        poly_coords.append(poly_coords[0])\n",
        "    polygons_list.append(Polygon(poly_coords))\n",
        "\n",
        "# Create a single MultiPolygon object for easier checking\n",
        "restricted_area = MultiPolygon(polygons_list)\n",
        "\n",
        "# =========================================================\n",
        "# 2. DOWNLOAD STREET NETWORK (The \"Reality\" Layer)\n",
        "# =========================================================\n",
        "print(\"Downloading street network from OpenStreetMap...\")\n",
        "\n",
        "# We download the street network around your average coordinates.\n",
        "# 'drive' ensures we don't snap to pedestrian paths inside buildings or parks if you need cars.\n",
        "# Use 'walk' if these are pedestrian clusters.\n",
        "center_lat = centroides_new[\"lat\"].mean()\n",
        "center_lon = centroides_new[\"lon\"].mean()\n",
        "\n",
        "# Download graph within 3km radius (adjust if your area is larger)\n",
        "G = ox.graph_from_point((center_lat, center_lon), dist=8000, network_type='walk')\n",
        "\n",
        "# Project graph to UTM (meters) for accurate nearest-node finding, then back to lat/lon\n",
        "# Note: For simple nearest node finding without strict meter precision, we can use the unprojected graph directly\n",
        "# with the newer osmnx functions, but creating a GeoDataFrame is safest.\n",
        "gdf_nodes = ox.graph_to_gdfs(G, edges=False)\n",
        "\n",
        "# =========================================================\n",
        "# 3. LOGIC TO MOVE CENTROIDS\n",
        "# =========================================================\n",
        "\n",
        "def correct_centroid_location(row):\n",
        "    # Create Point (Shapely uses Lon, Lat order)\n",
        "    current_point = Point(row['lon'], row['lat'])\n",
        "\n",
        "    # 1. CHECK RESTRICTED ZONES\n",
        "    if restricted_area.contains(current_point):\n",
        "        # Find nearest point on the boundary of the restricted area\n",
        "        # nearest_points returns tuple (geom1, geom2), we want the point on the polygon (index 1)\n",
        "        p1, p2 = nearest_points(current_point, restricted_area)\n",
        "        target_point = p1 # p1 is the point on the restricted_area boundary closest to current_point\n",
        "\n",
        "        # Update our \"current\" point to this new boundary location\n",
        "        current_point = target_point\n",
        "        status = \"Moved out of Zone\"\n",
        "    else:\n",
        "        status = \"Zone OK\"\n",
        "\n",
        "    # 2. SNAP TO REALITY (Avoid rivers/houses)\n",
        "    # We take the (potentially moved) point and find the nearest street node\n",
        "    nearest_node_id = ox.distance.nearest_nodes(G, current_point.x, current_point.y)\n",
        "    node_data = G.nodes[nearest_node_id]\n",
        "\n",
        "    # Update lat/lon to the street node's coordinates\n",
        "    new_lat = node_data['y']\n",
        "    new_lon = node_data['x']\n",
        "\n",
        "    return pd.Series([new_lat, new_lon, status])\n",
        "\n",
        "# =========================================================\n",
        "# 4. APPLY TO DATAFRAME\n",
        "# =========================================================\n",
        "print(\"Adjusting centroids...\")\n",
        "\n",
        "# Apply function with tqdm\n",
        "tqdm.pandas()\n",
        "centroides_new[['lat', 'lon', 'adjustment_status']] = centroides_new.progress_apply(correct_centroid_location, axis=1)\n",
        "\n",
        "print(\"Done! Centroids moved out of zones and snapped to nearest streets.\")\n",
        "centroides_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "4VADo0sBuEjP",
        "outputId": "7ad6b942-34ca-45a3-b157-b26bb9c056b9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "import numpy as np\n",
        "\n",
        "# 1. Convertir coordenadas a Radianes (Scikit-learn lo requiere así)\n",
        "# Asegúrate que el orden sea [Latitud, Longitud]\n",
        "points_rad = np.radians(combined_coords_df[['lat', 'lon']].to_numpy())\n",
        "centroids_rad = np.radians(centroides_new[['lat', 'lon']].to_numpy())\n",
        "\n",
        "# 2. Calcular matriz de distancias (Resultado en radianes)\n",
        "# Esto genera una matriz de tamaño (N_puntos x N_centroides)\n",
        "dist_matrix = haversine_distances(points_rad, centroids_rad)\n",
        "\n",
        "# 3. Encontrar el índice del valor mínimo por fila\n",
        "# (No hace falta convertir a metros para saber cuál es el menor)\n",
        "closest_centroid_indices = np.argmin(dist_matrix, axis=1)\n",
        "\n",
        "# 4. Asignar los IDs reales\n",
        "combined_coords_df['clusterFinal'] = centroides_new.iloc[closest_centroid_indices][\"cluster\"].values\n",
        "\n",
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDzhN4HPuHTg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(combined_coords_df.groupby('clusterFinal')['lat'].agg('count'), bins= 190)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu3wGDEevxwW",
        "outputId": "a9c295f1-850e-4c96-e4f8-572435146ae7"
      },
      "outputs": [],
      "source": [
        "combined_coords_df.drop('cluster_190', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WPe1TKWEPm7h",
        "outputId": "a9476533-7d16-4762-f014-1b5cbadca7a0"
      },
      "outputs": [],
      "source": [
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "o5-qUB1MP6_-",
        "outputId": "e47619a9-fc03-41f7-fcad-1814d33b2711"
      },
      "outputs": [],
      "source": [
        "centroides_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQtv7eEAvUtl"
      },
      "outputs": [],
      "source": [
        "combined_coords_df.to_csv('points_with_clusters2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tf6NSArwIrZ"
      },
      "outputs": [],
      "source": [
        "centroides_new.to_csv('centroides2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vquc_UNSKwP"
      },
      "source": [
        "## VIAJES CLUSTERIZADOS, EVALUACION DE ESTOS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm1mcFaNwTbV"
      },
      "outputs": [],
      "source": [
        "combined_coords_df = pd.read_csv('points_with_clusters2.csv')\n",
        "centroides_new = pd.read_csv('centroides2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "ueqmzv7e8YCT",
        "outputId": "69879129-4656-4021-a557-ab582ed17fbd"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURACIÓN\n",
        "# =========================================================\n",
        "colores = ['red', 'blue', 'green', 'grey', 'purple', 'orange',\n",
        "           'darkred', 'lightblue', 'cadetblue', 'darkgreen', 'pink']\n",
        "\n",
        "# Repetimos colores si hay más clusters que colores disponibles\n",
        "color_map = {}\n",
        "for idx, row1 in centroides_new.iterrows():\n",
        "    color_map[row1['cluster']] = colores[idx % len(colores)]\n",
        "\n",
        "# =========================================================\n",
        "# CREAR MAPA\n",
        "# =========================================================\n",
        "m = folium.Map(location=[41.90, 12.48], zoom_start=12)\n",
        "\n",
        "# Capa para cluster fusionado\n",
        "fused_layer = folium.FeatureGroup(name=\"Fused Centroids\").add_to(m)\n",
        "\n",
        "# Capa de círculos 50m para destinos aislados\n",
        "dest_radius_layer = folium.FeatureGroup(name=\"Destinations 50m Radius\").add_to(m)\n",
        "\n",
        "# Capa para los viajes\n",
        "trips_layer = folium.FeatureGroup(name=\"Trips\").add_to(m)\n",
        "\n",
        "# =========================================================\n",
        "# PINTAR CENTROIDES FUSIONADOS\n",
        "# =========================================================\n",
        "for _, row in centroides_new.iterrows():\n",
        "    cid = row[\"cluster\"]\n",
        "    lat = row[\"lat\"]\n",
        "    lon = row[\"lon\"]\n",
        "\n",
        "    # --- MARCADOR --- para el centroide\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        icon=folium.Icon(\n",
        "            icon=\"bolt\",\n",
        "            prefix=\"fa\",\n",
        "            color=color_map[cid]\n",
        "        ),\n",
        "        popup=(f\"<b>Cluster {cid}</b><br>lat: {lat:.5f}<br>lon: {lon:.5f}\")\n",
        "    ).add_to(fused_layer)\n",
        "\n",
        "# =========================================================\n",
        "# PINTAR LOS VIAJES PERTENECIENTES A CADA CLUSTER\n",
        "# =========================================================\n",
        "for _, row in combined_coords_df.iterrows():\n",
        "    trip_cluster = row[\"clusterFinal\"]  # El ID del cluster del viaje\n",
        "    trip_lat = row[\"lat\"]\n",
        "    trip_lon = row[\"lon\"]\n",
        "\n",
        "    # Asegurarse de que el viaje pertenece a un cluster válido\n",
        "    if trip_cluster in color_map:\n",
        "        # Añadir marcador para cada viaje\n",
        "        folium.CircleMarker(\n",
        "            location=[trip_lat, trip_lon],\n",
        "            radius=5,\n",
        "            color=color_map[trip_cluster],\n",
        "            fill=True,\n",
        "            fill_opacity=0.7,\n",
        "            popup=(f\"<b>Cluster: {trip_cluster}</b><br>Lat: {trip_lat:.5f}<br>Lon: {trip_lon:.5f}\")\n",
        "        ).add_to(trips_layer)\n",
        "\n",
        "# =========================================================\n",
        "# CAPAS\n",
        "# =========================================================\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "# Mostrar\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f693a989"
      },
      "source": [
        "## Distirbucion anclajes/desanclajes por cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e227ae2",
        "outputId": "aea468a5-a78c-4d90-a826-5cb65117abe9"
      },
      "outputs": [],
      "source": [
        "cluster_sizes = centroides_new['num_points']\n",
        "print(\"Extracted cluster sizes:\")\n",
        "print(cluster_sizes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3587bce8",
        "outputId": "733ffecd-0491-4cb4-c8ea-8a45345390fd"
      },
      "outputs": [],
      "source": [
        "bin_width = 20\n",
        "min_val = int(cluster_sizes.min() // bin_width * bin_width)\n",
        "max_val = int((cluster_sizes.max() // bin_width + 1) * bin_width)\n",
        "bins = list(range(min_val, max_val + bin_width, bin_width))\n",
        "\n",
        "bin_labels = [f\"{i}-{i+bin_width-1}\" for i in bins[:-1]]\n",
        "\n",
        "binned_data = pd.cut(cluster_sizes, bins=bins, labels=bin_labels, right=False)\n",
        "\n",
        "bin_counts = binned_data.value_counts().sort_index()\n",
        "\n",
        "print(\"Cluster counts per bin:\")\n",
        "print(bin_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crWsCoGw_8-W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd177c28"
      },
      "source": [
        "**Reasoning**:\n",
        "The data has been prepared with bins and their corresponding counts. Now, a bar chart needs to be generated to visualize the distribution of `num_points` per cluster, as requested in the main task. This will involve using `matplotlib.pyplot` to create a bar chart from `bin_counts`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "9f451806",
        "outputId": "4fcb098b-fdff-4e12-90ac-bafcc5c4a59a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.bar(bin_counts.index, bin_counts.values, color='skyblue')\n",
        "plt.xlabel('Number of Points Range (bin_width = 20)')\n",
        "plt.ylabel('Frequency of Clusters')\n",
        "plt.title('Distribution of Number of Points per Cluster (Bin Width = 20)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VzGGrY8AOPd",
        "outputId": "d2d87f0d-b977-4a00-e3ec-89c45c6ad890"
      },
      "outputs": [],
      "source": [
        "centroides_new['num_points'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-_januDR4n1"
      },
      "source": [
        "## VIAJES PERDIDOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7IHhbYuDVZb"
      },
      "outputs": [],
      "source": [
        "!pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "-Slssb89Arxk",
        "outputId": "d96e9915-d65b-4b0b-c0c6-0e8c9fd8375f"
      },
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "\n",
        "# Función que devuelve el tiempo máximo en segundos según el tipo de distancia\n",
        "def wait(dis):\n",
        "    if dis == 'corto':\n",
        "        return 300  # 5 minutos en segundos\n",
        "    elif dis == 'medio':\n",
        "        return 420  # 7 minutos en segundos\n",
        "    else:\n",
        "        return 600  # 10 minutos en segundos\n",
        "\n",
        "# Función que calcula la distancia máxima que una persona puede caminar\n",
        "# usando una velocidad de 5 km/h\n",
        "def max_distance(time_sec):\n",
        "    # 5 km/h -> 5000 metros por hora -> 83.33 metros por minuto -> 1.39 metros por segundo\n",
        "    velocity = 5 * 1000 / 3600  # 5 km/h en metros por segundo\n",
        "    return velocity * time_sec  # Distancia máxima en metros\n",
        "\n",
        "# Listas para almacenar los viajes perdidos según los criterios\n",
        "lost_trips = []\n",
        "\n",
        "# Recorremos cada viaje y verificamos si se encuentra dentro de la distancia máxima caminable\n",
        "for _, row in combined_coords_df.iterrows():\n",
        "    trip_cluster = row[\"clusterFinal\"]  # El ID del cluster del viaje\n",
        "    trip_lat = row[\"lat\"]\n",
        "    trip_lon = row[\"lon\"]\n",
        "    trip_type = row[\"type\"]  # corto, medio o largo\n",
        "\n",
        "    # Obtener el tiempo de espera máximo en segundos\n",
        "    max_wait_time = wait(trip_type)\n",
        "\n",
        "    # Calcular la distancia máxima que una persona puede caminar en el tiempo máximo\n",
        "    max_walk_distance = max_distance(max_wait_time)\n",
        "\n",
        "    # Obtener las coordenadas del cluster final al que pertenece el viaje\n",
        "    cluster_row = centroides_new[centroides_new['cluster'] == trip_cluster].iloc[0]\n",
        "    cluster_lat = cluster_row[\"lat\"]\n",
        "    cluster_lon = cluster_row[\"lon\"]\n",
        "\n",
        "    # Calcular la distancia entre el viaje y el centro del cluster final\n",
        "    distance_to_cluster = haversine((trip_lat, trip_lon), (cluster_lat, cluster_lon), unit=Unit.METERS)\n",
        "\n",
        "    # Si la distancia es mayor que la distancia máxima caminable, se considera un viaje perdido\n",
        "    if distance_to_cluster > max_walk_distance:\n",
        "        lost_trips.append({\n",
        "            'trip_cluster': trip_cluster,\n",
        "            'trip_lat': trip_lat,\n",
        "            'trip_lon': trip_lon,\n",
        "            'distance': distance_to_cluster,\n",
        "            'max_walk_distance': max_walk_distance\n",
        "        })\n",
        "\n",
        "# Mostrar los viajes perdidos\n",
        "lost_trips_df = pd.DataFrame(lost_trips)\n",
        "print(f\"Total de viajes perdidos: {len(lost_trips_df)}\")\n",
        "lost_trips_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "whlozt7vEDpX",
        "outputId": "4a290f16-d850-4e42-e484-727ad4dee985"
      },
      "outputs": [],
      "source": [
        "from haversine import haversine, Unit\n",
        "import pandas as pd\n",
        "\n",
        "# Función que devuelve el tiempo máximo en segundos según el tipo de distancia\n",
        "def wait(dis):\n",
        "    if dis == 'corto':\n",
        "        return 300  # 5 minutos en segundos\n",
        "    elif dis == 'medio':\n",
        "        return 420  # 7 minutos en segundos\n",
        "    else:\n",
        "        return 600  # 10 minutos en segundos\n",
        "\n",
        "# Función que calcula la distancia máxima que una persona puede caminar\n",
        "# usando una velocidad de 5 km/h\n",
        "def max_distance(time_sec):\n",
        "    # 5 km/h -> 5000 metros por hora -> 83.33 metros por minuto -> 1.39 metros por segundo\n",
        "    velocity = 5 * 1000 / 3600  # 5 km/h en metros por segundo\n",
        "    return velocity * time_sec  # Distancia máxima en metros\n",
        "\n",
        "# Lista para almacenar los viajes perdidos según los criterios\n",
        "lost_trips = []\n",
        "\n",
        "# Total de puntos en combined_coords_df\n",
        "total_points = len(combined_coords_df)\n",
        "\n",
        "# Recorrer cada par de origen y destino (los primeros 24000 son orígenes, el resto son destinos)\n",
        "for i in range(total_points // 2):\n",
        "    # Origen (primer mitad de los puntos)\n",
        "    origin_row = combined_coords_df.iloc[i]\n",
        "    origin_lat = origin_row[\"lat\"]\n",
        "    origin_lon = origin_row[\"lon\"]\n",
        "    origin_type = origin_row[\"type\"]  # tipo de distancia (corto, medio, largo)\n",
        "    origin_cluster = origin_row[\"clusterFinal\"]  # cluster al que pertenece el origen\n",
        "\n",
        "    # Obtener las coordenadas del centroide del cluster de origen\n",
        "    origin_cluster_row = centroides_new[centroides_new['cluster'] == origin_cluster].iloc[0]\n",
        "    origin_cluster_lat = origin_cluster_row[\"lat\"]\n",
        "    origin_cluster_lon = origin_cluster_row[\"lon\"]\n",
        "\n",
        "    # Destino (segunda mitad de los puntos)\n",
        "    destination_row = combined_coords_df.iloc[i + total_points // 2]\n",
        "    dest_lat = destination_row[\"lat\"]\n",
        "    dest_lon = destination_row[\"lon\"]\n",
        "    dest_type = destination_row[\"type\"]  # tipo de distancia (corto, medio, largo)\n",
        "    dest_cluster = destination_row[\"clusterFinal\"]  # cluster al que pertenece el destino\n",
        "\n",
        "    # Obtener las coordenadas del centroide del cluster de destino\n",
        "    dest_cluster_row = centroides_new[centroides_new['cluster'] == dest_cluster].iloc[0]\n",
        "    dest_cluster_lat = dest_cluster_row[\"lat\"]\n",
        "    dest_cluster_lon = dest_cluster_row[\"lon\"]\n",
        "\n",
        "    # Obtener el tiempo máximo de espera (dependiendo del tipo de distancia)\n",
        "    max_wait_time = wait(origin_type)  # Usamos el tipo de distancia del origen\n",
        "\n",
        "    # Calcular la distancia máxima caminable\n",
        "    max_walk_distance = max_distance(max_wait_time)\n",
        "\n",
        "    # Calcular la distancia entre el origen y su centroide de cluster\n",
        "    origin_distance_to_cluster = haversine((origin_lat, origin_lon), (origin_cluster_lat, origin_cluster_lon), unit=Unit.METERS)\n",
        "\n",
        "    # Calcular la distancia entre el destino y su centroide de cluster\n",
        "    dest_distance_to_cluster = haversine((dest_lat, dest_lon), (dest_cluster_lat, dest_cluster_lon), unit=Unit.METERS)\n",
        "\n",
        "    # Verificar si el origen o el destino están fuera del alcance caminable\n",
        "    if origin_distance_to_cluster > max_walk_distance or dest_distance_to_cluster > max_walk_distance:\n",
        "        lost_trips.append({\n",
        "            'origin_cluster': origin_cluster,\n",
        "            'destination_cluster': dest_cluster,\n",
        "            'origin_lat': origin_lat,\n",
        "            'origin_lon': origin_lon,\n",
        "            'destination_lat': dest_lat,\n",
        "            'destination_lon': dest_lon,\n",
        "            'origin_distance': origin_distance_to_cluster,\n",
        "            'destination_distance': dest_distance_to_cluster,\n",
        "            'max_walk_distance': max_walk_distance,\n",
        "            'reason': 'Exceeds maximum walkable distance'\n",
        "        })\n",
        "\n",
        "    # También considerar el viaje como perdido si el origen y el destino están en el mismo cluster\n",
        "    elif origin_cluster == dest_cluster:\n",
        "        lost_trips.append({\n",
        "            'origin_cluster': origin_cluster,\n",
        "            'destination_cluster': dest_cluster,\n",
        "            'origin_lat': origin_lat,\n",
        "            'origin_lon': origin_lon,\n",
        "            'destination_lat': dest_lat,\n",
        "            'destination_lon': dest_lon,\n",
        "            'origin_distance': 'N/A',  # No se calcula la distancia, ya que es un viaje perdido por el mismo cluster\n",
        "            'destination_distance': 'N/A',\n",
        "            'max_walk_distance': 'N/A',\n",
        "            'reason': 'Same origin and destination cluster'\n",
        "        })\n",
        "\n",
        "# Convertir la lista de viajes perdidos en un DataFrame\n",
        "lost_trips_df = pd.DataFrame(lost_trips)\n",
        "\n",
        "# Mostrar el número total de viajes perdidos\n",
        "total_lost = len(lost_trips_df)\n",
        "total_trips = total_points // 2  # Número total de viajes (ya que hay un origen y un destino por viaje)\n",
        "proportion_lost = total_lost / total_trips * 100\n",
        "\n",
        "print(f\"Total de viajes perdidos: {total_lost}\")\n",
        "print(f\"Proporción de viajes perdidos: {proportion_lost:.2f}%\")\n",
        "\n",
        "# Mostrar los primeros 5 viajes perdidos\n",
        "lost_trips_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5lukzgdgT2H6",
        "outputId": "f7767c23-78db-4138-b2b4-2a25ff65b2ff"
      },
      "outputs": [],
      "source": [
        "combined_coords_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "NrwUvaoGTJiL",
        "outputId": "ed424c21-35f3-44ba-9646-d15cff2f5553"
      },
      "outputs": [],
      "source": [
        "df = df.merge(combined_coords_df[['lon', 'lat', 'clusterFinal']],\n",
        "              left_on=['lonO', 'latO'],\n",
        "              right_on=['lon', 'lat'],\n",
        "              how='left')\n",
        "print(f\"Número de filas después del primer merge: {len(df)}\")\n",
        "\n",
        "# Renombrar la columna 'clusterFinal' obtenida del merge para 'clusterOrigen'\n",
        "df.rename(columns={'clusterFinal': 'clusterOrigen'}, inplace=True)\n",
        "\n",
        "# Merge para asignar clusterFinal basado en las coordenadas de destino (lonD, latD)\n",
        "df = df.merge(combined_coords_df[['lon', 'lat', 'clusterFinal']],\n",
        "              left_on=['lonD', 'latD'],\n",
        "              right_on=['lon', 'lat'],\n",
        "              how='left')\n",
        "\n",
        "# Renombrar la columna 'clusterFinal' obtenida del merge para 'clusterFinal'\n",
        "df.rename(columns={'clusterFinal': 'clusterFinal'}, inplace=True)\n",
        "print(f\"Número de filas después del primer merge: {len(df)}\")\n",
        "\n",
        "# Mostrar el resultado\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS9vnTwHU8Bw"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset=['lonO',\t'latO',\t'lonD'\t,'latD'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "uaqX1YhkVQ_T",
        "outputId": "985deebf-f002-4edd-867a-1e35fa958eb1"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "Fl45JGKOL9q_",
        "outputId": "0fe5f347-6497-47da-ab43-c1ed0e107a00"
      },
      "outputs": [],
      "source": [
        "# Eliminar las columnas lonO, latO, lonD, latD\n",
        "df = df.drop(columns=['lon_x', 'lat_x', 'lon_y', 'lat_y'])\n",
        "\n",
        "# Mostrar e resultado\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "WzYlfm0-MEhD",
        "outputId": "c0583371-0855-469a-ff0f-14f851ee7504"
      },
      "outputs": [],
      "source": [
        "lost_trips_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "06lHFTFYV2Pw",
        "outputId": "c8c5b2c0-89cd-4dca-e0f8-e82c472994aa"
      },
      "outputs": [],
      "source": [
        "# Realizar un merge entre df y lost_trips para encontrar las filas coincidentes\n",
        "merged_df = df.merge(lost_trips_df[['origin_lat', 'origin_lon', 'destination_lat', 'destination_lon']],\n",
        "                     left_on=['latO', 'lonO', 'latD', 'lonD'],\n",
        "                     right_on=['origin_lat', 'origin_lon', 'destination_lat', 'destination_lon'],\n",
        "                     how='left', indicator=True)\n",
        "\n",
        "# Filtrar aquellas filas que no están en lost_trips (es decir, las filas donde el indicador no es 'both')\n",
        "df_final = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
        "\n",
        "# Mostrar el DataFrame limpio\n",
        "df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgUj1j7fWX7V"
      },
      "outputs": [],
      "source": [
        "df_final.to_csv(\"potenciales_viajes_cubiertos.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pjCP88XWvAC",
        "outputId": "e9d658e0-1167-4482-f659-c6c330da3368"
      },
      "outputs": [],
      "source": [
        "sum(df_final['price'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fP0Xyk7XGF1",
        "outputId": "1c7478ad-e07c-4ef1-df09-266c4d0f11d0"
      },
      "outputs": [],
      "source": [
        "len(df_final['idS'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNUQ40aUZCJq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
